2020-09-15 16:31:14,296 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,297 Model: "TextClassifier(
  (document_embeddings): TransformerDocumentEmbeddings(
    (model): DistilBertModel(
      (embeddings): Embeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (transformer): Transformer(
        (layer): ModuleList(
          (0): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
          (1): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
          (2): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
          (3): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
          (4): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
          (5): TransformerBlock(
            (attention): MultiHeadSelfAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (q_lin): Linear(in_features=768, out_features=768, bias=True)
              (k_lin): Linear(in_features=768, out_features=768, bias=True)
              (v_lin): Linear(in_features=768, out_features=768, bias=True)
              (out_lin): Linear(in_features=768, out_features=768, bias=True)
            )
            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (ffn): FFN(
              (dropout): Dropout(p=0.1, inplace=False)
              (lin1): Linear(in_features=768, out_features=3072, bias=True)
              (lin2): Linear(in_features=3072, out_features=768, bias=True)
            )
            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          )
        )
      )
    )
  )
  (decoder): Linear(in_features=768, out_features=5, bias=True)
  (loss_function): CrossEntropyLoss()
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-09-15 16:31:14,297 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,298 Corpus: "Corpus: 1557 train + 334 dev + 334 test sentences"
2020-09-15 16:31:14,298 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,298 Parameters:
2020-09-15 16:31:14,298  - learning_rate: "3e-05"
2020-09-15 16:31:14,298  - mini_batch_size: "16"
2020-09-15 16:31:14,298  - patience: "3"
2020-09-15 16:31:14,298  - anneal_factor: "0.5"
2020-09-15 16:31:14,298  - max_epochs: "5"
2020-09-15 16:31:14,298  - shuffle: "True"
2020-09-15 16:31:14,299  - train_with_dev: "False"
2020-09-15 16:31:14,299  - batch_growth_annealing: "False"
2020-09-15 16:31:14,299 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,299 Model training base path: "classify/model"
2020-09-15 16:31:14,299 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,299 Device: cpu
2020-09-15 16:31:14,299 ----------------------------------------------------------------------------------------------------
2020-09-15 16:31:14,299 Embeddings storage mode: cpu
2020-09-15 16:31:14,301 ----------------------------------------------------------------------------------------------------
2020-09-15 16:35:36,433 epoch 1 - iter 9/98 - loss 1.43148057 - samples/sec: 0.55 - lr: 0.000030
2020-09-15 16:40:17,617 epoch 1 - iter 18/98 - loss 1.01889119 - samples/sec: 0.51 - lr: 0.000030
2020-09-15 16:44:24,775 epoch 1 - iter 27/98 - loss 0.75528147 - samples/sec: 0.58 - lr: 0.000030
2020-09-15 16:48:27,604 epoch 1 - iter 36/98 - loss 0.59176874 - samples/sec: 0.59 - lr: 0.000030
2020-09-15 16:52:33,669 epoch 1 - iter 45/98 - loss 0.48109400 - samples/sec: 0.59 - lr: 0.000030
2020-09-15 16:56:38,278 epoch 1 - iter 54/98 - loss 0.40692385 - samples/sec: 0.59 - lr: 0.000030
2020-09-15 17:00:45,355 epoch 1 - iter 63/98 - loss 0.34970249 - samples/sec: 0.58 - lr: 0.000030
2020-09-15 17:04:46,403 epoch 1 - iter 72/98 - loss 0.30896607 - samples/sec: 0.60 - lr: 0.000030
2020-09-15 17:08:54,328 epoch 1 - iter 81/98 - loss 0.27473471 - samples/sec: 0.58 - lr: 0.000030
2020-09-15 17:12:58,583 epoch 1 - iter 90/98 - loss 0.27726456 - samples/sec: 0.59 - lr: 0.000030
2020-09-15 17:16:33,738 ----------------------------------------------------------------------------------------------------
2020-09-15 17:16:33,738 EPOCH 1 done: loss 0.2549 - lr 0.0000300
2020-09-15 17:19:05,636 DEV : loss 0.12346922606229782 - score 0.9701
2020-09-15 17:19:12,306 BAD EPOCHS (no improvement): 0
2020-09-15 17:19:14,891 ----------------------------------------------------------------------------------------------------
2020-09-15 17:23:29,331 epoch 2 - iter 9/98 - loss 0.02987691 - samples/sec: 0.57 - lr: 0.000030
